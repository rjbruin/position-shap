{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toy 00: testing toy setting with linear models\n",
    "\n",
    "HOWTO: run the dataset & model cells, then run either of the solution cells following by the analysis cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset & model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "def get_inputs(n=1, size=[5,5]):\n",
    "    return torch.ones([n, 3] + size)\n",
    "\n",
    "def get_inputs_cutoffneuron_pixelimage(n=1, size=[5,5]):\n",
    "    im = torch.ones([n, 3] + size)\n",
    "    pe = torch.zeros([n, 1] + size)\n",
    "    pe[:, :, 2, 2] = 1\n",
    "    return im, pe\n",
    "\n",
    "def get_inputs_cutoffneuron_discpe(size=[5,5]):\n",
    "    im = torch.zeros([2, 3] + size)\n",
    "    im[0, :, 1, 1] = 1\n",
    "    im[1, :, 3, 3] = 1\n",
    "    lab = torch.tensor([0, 1]).unsqueeze(1)\n",
    "    pe = torch.zeros([2, 1] + size)\n",
    "    pe[:, :, :, :2] = 1\n",
    "    pe[:, :, :, 3:] = -1\n",
    "    return im, lab, pe\n",
    "\n",
    "images = get_inputs()\n",
    "labels = torch.tensor([0]).unsqueeze(0).repeat(images.size(0), 1)\n",
    "\n",
    "con_pi_images, con_pi_pe = get_inputs_cutoffneuron_pixelimage()\n",
    "con_dp_images, con_dp_labels, con_dp_pe = get_inputs_cutoffneuron_discpe()\n",
    "\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, size, pos_emb, bias, solution='c0:image'):\n",
    "        super().__init__()\n",
    "        self.solution = solution\n",
    "        self.pos_emb = pos_emb\n",
    "        self.bias = nn.Parameter(bias)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        if inputs.shape[0] != 1:\n",
    "            raise NotImplementedError(\"Only batch size 1 is supported\")\n",
    "        self.image_in = inputs\n",
    "        self.pos_emb_in = self.pos_emb\n",
    "        self.image_in.requires_grad = True\n",
    "        self.pos_emb_in.requires_grad = True\n",
    "\n",
    "        x = self.image_in\n",
    "        y = self.pos_emb_in\n",
    "\n",
    "        if self.solution == 'c0:image':\n",
    "            class_0 = x.mean() + (self.bias * 0.).sum()\n",
    "            class_1 = y.mean() * 0.\n",
    "        elif self.solution == 'c0:pos':\n",
    "            class_0 = y.mean() + (self.bias * 0.).sum()\n",
    "            class_1 = x.mean() * 0.\n",
    "        elif self.solution == 'c0:bias':\n",
    "            class_0 = (x.mean() * 0.) + (self.bias).sum()\n",
    "            class_1 = y.mean() * 0.\n",
    "        elif self.solution == 'c0:image+noisepos0.1':\n",
    "            noise = torch.randn_like(y) * 0.1\n",
    "            class_0 = x.mean() + (y * noise).mean() + (self.bias * 0.).sum()\n",
    "            class_1 = y.mean() * 0.\n",
    "        elif self.solution == 'c0:image+noisepos0.5':\n",
    "            noise = torch.randn_like(y) * 0.5\n",
    "            class_0 = x.mean() + (y * noise).mean() + (self.bias * 0.).sum()\n",
    "            class_1 = y.mean() * 0.\n",
    "        # Toys for debugging problems with nonlinearities\n",
    "        elif self.solution == 'cutoffneuron:pixelimage':\n",
    "            cutoffneuron = torch.relu(-x + 2. * y)\n",
    "            class_0 = cutoffneuron.mean() + (self.bias * 0.).sum()\n",
    "            # print(cutoffneuron[:,:,0,0].mean(), cutoffneuron[:,:,2,2].mean())\n",
    "            class_1 = y.mean() * 0.\n",
    "        elif self.solution == 'cutoffneuron:discpe':\n",
    "            neuron_im = torch.relu(-0.5 + x)\n",
    "            # print(neuron_im[0,0])\n",
    "            cutoffneuron_c0 = torch.relu(neuron_im * y)\n",
    "            cutoffneuron_c1 = torch.relu(neuron_im * -y)\n",
    "            class_0 = cutoffneuron_c0.mean() + (self.bias * 0.).sum()\n",
    "            class_1 = cutoffneuron_c1.mean() + (self.bias * 0.).sum()\n",
    "            # class_1 = y.mean() * 0.\n",
    "        else:\n",
    "            raise NotImplementedError(f\"Solution {self.solution} not implemented\")\n",
    "\n",
    "        return torch.stack([class_0, class_1]).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7311, 0.2689], grad_fn=<SoftmaxBackward0>) tensor(0.3133, grad_fn=<DivBackward1>)\n"
     ]
    }
   ],
   "source": [
    "x = get_input()\n",
    "y = get_input() * 0.\n",
    "x.requires_grad = True\n",
    "y.requires_grad = True\n",
    "gt_probs = torch.tensor([1., 0.])\n",
    "model = SimpleNet(x.size())\n",
    "logits = model([x, y])\n",
    "probs = torch.softmax(logits, dim=0)\n",
    "loss = torch.nn.functional.cross_entropy(logits, gt_probs)\n",
    "(-loss).backward()\n",
    "print(probs, loss)\n",
    "# print(x * x.grad, y * y.grad)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "import numpy as np\n",
    "\n",
    "import training\n",
    "import utils\n",
    "\n",
    "\n",
    "def run_debug(seeds, solution, pos_emb, bias, analysis_images, analysis_labels, n_classes, attribution_method='input_gradient_withnegative', aggregate_fn='sum', target='pred_class', ):\n",
    "    biases = {'bias': [], 'appearance': [], 'position': [], 'relative_position': []}\n",
    "    biases_withbias = {'bias': [], 'appearance': [], 'position': [], 'relative_position': []}\n",
    "    cls_biases = {c: {'bias': [], 'appearance': [], 'position': [], 'relative_position': []} for c in range(n_classes)}\n",
    "    cls_biases_withbias = {c: {'bias': [], 'appearance': [], 'position': [], 'relative_position': []} for c in range(n_classes)}\n",
    "    models = []\n",
    "    for seed in seeds:\n",
    "        torch.manual_seed(seed)\n",
    "        model = SimpleNet([5, 5], pos_emb.clone(), bias.clone(), solution)\n",
    "\n",
    "        # Analysis\n",
    "        n_samples = None\n",
    "        targets = [target]\n",
    "        shape = 'scalar'\n",
    "        patch_size = 1\n",
    "        attribution_method = 'input_gradient'\n",
    "        aggregate_fn = 'sum'\n",
    "\n",
    "        seed_biases, seed_biases_withbias, seed_cls_biases, seed_cls_biases_withbias = \\\n",
    "            utils.toy_all_analyses(model, analysis_images, analysis_labels, n_classes, seed, sources_available=['image', 'pos_emb', 'bias'], attribution_method=attribution_method, aggregate_fn=aggregate_fn, target=target)\n",
    "\n",
    "        for key in seed_biases:\n",
    "            biases[key].append(seed_biases[key])\n",
    "            for c in range(n_classes):\n",
    "                if c in seed_cls_biases:\n",
    "                    cls_biases[c][key].append(seed_cls_biases[c][key])\n",
    "\n",
    "        for key in seed_biases_withbias:\n",
    "            biases_withbias[key].append(seed_biases_withbias[key])\n",
    "            for c in range(n_classes):\n",
    "                if c in seed_cls_biases_withbias:\n",
    "                    cls_biases_withbias[c][key].append(seed_cls_biases_withbias[c][key])\n",
    "\n",
    "        models.append(model)\n",
    "\n",
    "    utils.toy_postprocess_analysis(biases, biases_withbias, cls_biases, cls_biases_withbias, seeds, n_classes, sort_by_appearance=False)\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Cut off neuron\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Without bias:\n",
      "appearance (all): 73.33 +- 0.00 (73.33, 73.33, 73.33, 73.33, 73.33, 73.33, 73.33, 73.33, 73.33, 73.33)\n",
      "appearance (c0) : 44.44 +- 0.00 (44.44, 44.44, 44.44, 44.44, 44.44, 44.44, 44.44, 44.44, 44.44, 44.44)\n",
      "appearance (c1) : 40.00 +- 0.00 (40.00, 40.00, 40.00, 40.00, 40.00, 40.00, 40.00, 40.00, 40.00, 40.00)\n",
      "position (all): 26.67 +- 0.00 (26.67, 26.67, 26.67, 26.67, 26.67, 26.67, 26.67, 26.67, 26.67, 26.67)\n",
      "position (c0) : 55.56 +- 0.00 (55.56, 55.56, 55.56, 55.56, 55.56, 55.56, 55.56, 55.56, 55.56, 55.56)\n",
      "position (c1) : 60.00 +- 0.00 (60.00, 60.00, 60.00, 60.00, 60.00, 60.00, 60.00, 60.00, 60.00, 60.00)\n",
      "\n",
      "With bias:\n",
      "bias (all): 0.00 +- 0.00 (0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00)\n",
      "bias (c0) : 0.00 +- 0.00 (0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00)\n",
      "bias (c1) : 0.00 +- 0.00 (0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00)\n",
      "appearance (all): 53.57 +- 0.00 (53.57, 53.57, 53.57, 53.57, 53.57, 53.57, 53.57, 53.57, 53.57, 53.57)\n",
      "appearance (c0) : 36.36 +- 0.00 (36.36, 36.36, 36.36, 36.36, 36.36, 36.36, 36.36, 36.36, 36.36, 36.36)\n",
      "appearance (c1) : 33.33 +- 0.00 (33.33, 33.33, 33.33, 33.33, 33.33, 33.33, 33.33, 33.33, 33.33, 33.33)\n",
      "position (all): 46.43 +- 0.00 (46.43, 46.43, 46.43, 46.43, 46.43, 46.43, 46.43, 46.43, 46.43, 46.43)\n",
      "position (c0) : 63.64 +- 0.00 (63.64, 63.64, 63.64, 63.64, 63.64, 63.64, 63.64, 63.64, 63.64, 63.64)\n",
      "position (c1) : 66.67 +- 0.00 (66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "\n",
    "\"\"\"\n",
    "Solution \"cutoffneuron:pixelimage\" - counterexample to show how saliency does not work for non-linearities\n",
    "Expectation:\n",
    "    overall:    0% bias     33% appearance  16% position\n",
    "    class 0:    0% bias     66% appearance  33% position\n",
    "    class 1:    0% bias     0% appearance   0% position\n",
    "\"\"\"\n",
    "seeds = range(10)\n",
    "n_classes = 2\n",
    "solution = 'cutoffneuron:discpe'\n",
    "# target = 'logits_all_class'\n",
    "target = 'pred_class'\n",
    "bias = torch.tensor([0.])\n",
    "models = run_debug(seeds, solution, con_dp_pe.clone(), bias, con_dp_images.clone(), con_dp_labels.clone(), n_classes, target=target)\n",
    "\n",
    "# solution = 'cutoffneuron:pixelimage'\n",
    "# # target = 'pred_class'\n",
    "# target = 'logits_all_class'\n",
    "# bias = torch.tensor([0.])\n",
    "# models = run_debug(seeds, solution, con_pi_pe.clone(), bias, con_pi_images.clone(), labels.clone(), n_classes, target=target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug - fix zero grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Without bias:\n",
      "appearance (all): 83.41 +- 1.75 (82.88, 86.05, 85.02, 82.17, 82.44, 80.59, 85.28, 85.31, 82.56, 81.80)\n",
      "appearance (c0) : 62.71 +- 2.98 (61.73, 67.27, 65.43, 60.57, 61.02, 58.06, 65.88, 65.94, 61.20, 59.97)\n",
      "position (all): 16.59 +- 1.75 (17.12, 13.95, 14.98, 17.83, 17.56, 19.41, 14.72, 14.69, 17.44, 18.20)\n",
      "position (c0) : 37.29 +- 2.98 (38.27, 32.73, 34.57, 39.43, 38.98, 41.94, 34.12, 34.06, 38.80, 40.03)\n",
      "\n",
      "With bias:\n",
      "bias (all): 0.00 +- 0.00 (0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00)\n",
      "bias (c0) : 0.00 +- 0.00 (0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00)\n",
      "appearance (all): 71.58 +- 2.58 (70.76, 75.51, 73.95, 69.73, 70.13, 67.50, 74.34, 74.39, 70.29, 69.20)\n",
      "appearance (c0) : 55.80 +- 3.14 (54.75, 60.65, 58.67, 53.53, 54.00, 50.94, 59.16, 59.22, 54.19, 52.91)\n",
      "position (all): 28.42 +- 2.58 (29.24, 24.49, 26.05, 30.27, 29.87, 32.50, 25.66, 25.61, 29.71, 30.80)\n",
      "position (c0) : 44.20 +- 3.14 (45.25, 39.35, 41.33, 46.47, 46.00, 49.06, 40.84, 40.78, 45.81, 47.09)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "\n",
    "\"\"\"\n",
    "Solution \"c0:image\"\n",
    "Expectation:\n",
    "    overall:    0% bias     50% appearance  0% position\n",
    "    class 0:    0% bias     100% appearance 0% position\n",
    "    class 1:    0% bias     0% appearance   0% position\n",
    "\"\"\"\n",
    "seeds = range(10)\n",
    "n_classes = 2\n",
    "solution = 'c0:image+noisepos0.5'\n",
    "# target = 'pred_class'\n",
    "target = 'logits_all_class'\n",
    "pos_emb = images[0:1].clone()\n",
    "bias = torch.tensor([0.])\n",
    "models = run_debug(seeds, solution, pos_emb, bias, images.clone(), labels.clone(), n_classes, target=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Without bias:\n",
      "appearance (all): 100.00 +- 0.00 (100.00)\n",
      "appearance (c0) : 100.00 +- 0.00 (100.00)\n",
      "position (all): 0.00 +- 0.00 (0.00)\n",
      "position (c0) : 0.00 +- 0.00 (0.00)\n",
      "\n",
      "With bias:\n",
      "bias (all): 0.00 +- 0.00 (0.00)\n",
      "bias (c0) : 0.00 +- 0.00 (0.00)\n",
      "appearance (all): 100.00 +- 0.00 (100.00)\n",
      "appearance (c0) : 100.00 +- 0.00 (100.00)\n",
      "position (all): 0.00 +- 0.00 (0.00)\n",
      "position (c0) : 0.00 +- 0.00 (0.00)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "\n",
    "\"\"\"\n",
    "Solution \"c0:image\"\n",
    "Expectation:\n",
    "    overall:    0% bias     50% appearance  0% position\n",
    "    class 0:    0% bias     100% appearance 0% position\n",
    "    class 1:    0% bias     0% appearance   0% position\n",
    "\"\"\"\n",
    "seeds = [0]\n",
    "n_classes = 2\n",
    "solution = 'c0:image'\n",
    "# target = 'pred_class'\n",
    "target = 'logits_all_class'\n",
    "pos_emb = images[0:1].clone()\n",
    "bias = torch.tensor([0.])\n",
    "models = run_debug(seeds, solution, pos_emb, bias, images, labels, n_classes, target=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Without bias:\n",
      "appearance (all): 0.00 +- 0.00 (0.00)\n",
      "appearance (c0) : 0.00 +- 0.00 (0.00)\n",
      "position (all): 100.00 +- 0.00 (100.00)\n",
      "position (c0) : 100.00 +- 0.00 (100.00)\n",
      "\n",
      "With bias:\n",
      "bias (all): 0.00 +- 0.00 (0.00)\n",
      "bias (c0) : 0.00 +- 0.00 (0.00)\n",
      "appearance (all): 0.00 +- 0.00 (0.00)\n",
      "appearance (c0) : 0.00 +- 0.00 (0.00)\n",
      "position (all): 100.00 +- 0.00 (100.00)\n",
      "position (c0) : 100.00 +- 0.00 (100.00)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "\n",
    "\"\"\"\n",
    "Solution \"c0:pos\"\n",
    "Expectation:\n",
    "    overall:    0% bias     0% appearance   100% position\n",
    "    class 0:    0% bias     0% appearance   100% position\n",
    "\"\"\"\n",
    "seeds = [0]\n",
    "n_classes = 2\n",
    "solution = 'c0:pos'\n",
    "# target = 'pred_class'\n",
    "target = 'logits_all_class'\n",
    "pos_emb = images[0:1].clone()\n",
    "bias = torch.tensor([0.])\n",
    "models = run_debug(seeds, solution, pos_emb, bias, images, labels, n_classes, target=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Without bias:\n",
      "appearance (all): 0.00 +- 0.00 (0.00)\n",
      "appearance (c0) : 0.00 +- 0.00 (0.00)\n",
      "position (all): 0.00 +- 0.00 (0.00)\n",
      "position (c0) : 0.00 +- 0.00 (0.00)\n",
      "\n",
      "With bias:\n",
      "bias (all): 100.00 +- 0.00 (100.00)\n",
      "bias (c0) : 100.00 +- 0.00 (100.00)\n",
      "appearance (all): 0.00 +- 0.00 (0.00)\n",
      "appearance (c0) : 0.00 +- 0.00 (0.00)\n",
      "position (all): 0.00 +- 0.00 (0.00)\n",
      "position (c0) : 0.00 +- 0.00 (0.00)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "\n",
    "\"\"\"\n",
    "Solution \"c0:bias\"\n",
    "Expectation:\n",
    "    overall:    100% bias     0% appearance   0% position\n",
    "    class 0:    100% bias     0% appearance   0% position\n",
    "\"\"\"\n",
    "seeds = [0]\n",
    "n_classes = 2\n",
    "solution = 'c0:bias'\n",
    "# target = 'pred_class'\n",
    "target = 'logits_all_class'\n",
    "pos_emb = images[0:1].clone()\n",
    "bias = torch.tensor([1.])\n",
    "models = run_debug(seeds, solution, pos_emb, bias, images, labels, n_classes, target=target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saliency SNR: nandB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robert-jan/surfdrive/experiments/vit-position-info/toy-experiments/utils.py:448: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  snr = 10. * np.log10(signal_mean / noise_mean)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x200 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%autoreload\n",
    "from utils import visualize_sensitivities\n",
    "\n",
    "seed = 1\n",
    "\n",
    "n = len(images)\n",
    "# n = 10\n",
    "# manual_sort = [\n",
    "#     0, 7, 14, 21, 28,\n",
    "#     2, 9, 16, 23, 30,\n",
    "#     4, 11, 18, 25, 32,\n",
    "#     6, 13, 20, 27, 34,\n",
    "#     1, 8, 15, 22, 29,\n",
    "#     3, 10, 17, 24, 31,\n",
    "#     5, 12, 19, 26, 33,\n",
    "# ]\n",
    "sort = 'appearance'\n",
    "visualize_sensitivities(models[0], seed, images, labels, ape=True, rpe=False, sort=sort, n=n, snr_signal=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saliency SNR: 41.6383dB\n",
      "Image saliency SNR: 41.4812dB\n",
      "Image saliency SNR: 40.8945dB\n",
      "Image saliency SNR: 41.3671dB\n",
      "Image saliency SNR: 40.8666dB\n",
      "Image saliency SNR: 40.8912dB\n",
      "Image saliency SNR: 40.5793dB\n",
      "Image saliency SNR: 40.9723dB\n",
      "Image saliency SNR: 41.4958dB\n",
      "Image saliency SNR: 40.9665dB\n",
      "41.11527186687455 0.33262905946192\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "from utils import visualize_sensitivities\n",
    "\n",
    "# seed = 1\n",
    "\n",
    "n = len(analysis_images)\n",
    "# n = 10\n",
    "# manual_sort = [\n",
    "#     0, 7, 14, 21, 28,\n",
    "#     2, 9, 16, 23, 30,\n",
    "#     4, 11, 18, 25, 32,\n",
    "#     6, 13, 20, 27, 34,\n",
    "#     1, 8, 15, 22, 29,\n",
    "#     3, 10, 17, 24, 31,\n",
    "#     5, 12, 19, 26, 33,\n",
    "# ]\n",
    "sort = 'appearance'\n",
    "\n",
    "snrs = []\n",
    "for seed in seeds:\n",
    "    snrs.append(visualize_sensitivities(models[seed], seed, analysis_images, analysis_labels, ape=True, rpe=True, sort=sort, n=n, snr_signal='appearance', only_snr=True))\n",
    "\n",
    "snrs = np.array(snrs)\n",
    "print(np.mean(snrs), np.std(snrs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No PE - fixed zero grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 0.7221008539199829\n",
      "Epoch 2000: 0.02107856422662735\n",
      "Epoch 3999: 0.002895661862567067\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.7210021018981934\n",
      "Epoch 2000: 0.020834438502788544\n",
      "Epoch 3999: 0.002863737754523754\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.7215662598609924\n",
      "Epoch 2000: 0.023010142147541046\n",
      "Epoch 3999: 0.0030359893571585417\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 1.0340348482131958\n",
      "Epoch 2000: 0.03455383703112602\n",
      "Epoch 3999: 0.004102038219571114\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.7439739108085632\n",
      "Epoch 2000: 0.024278920143842697\n",
      "Epoch 3999: 0.003159926040098071\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.9646301865577698\n",
      "Epoch 2000: 0.027945375069975853\n",
      "Epoch 3999: 0.003468348877504468\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.7156517505645752\n",
      "Epoch 2000: 0.020956415683031082\n",
      "Epoch 3999: 0.002880038693547249\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.6986721754074097\n",
      "Epoch 2000: 0.02056218683719635\n",
      "Epoch 3999: 0.0028406335040926933\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.8546369075775146\n",
      "Epoch 2000: 0.02559121698141098\n",
      "Epoch 3999: 0.003306324128061533\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.8437312841415405\n",
      "Epoch 2000: 0.03035678155720234\n",
      "Epoch 3999: 0.003567566629499197\n",
      "Accuracy: 1.0\n",
      "\n",
      "Without bias:\n",
      "appearance (all): 100.00 +- 0.00 (100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00)\n",
      "appearance (c0) : 100.00 +- 0.00 (100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00)\n",
      "appearance (c1) : 100.00 +- 0.00 (100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00)\n",
      "\n",
      "With bias:\n",
      "bias (all): 70.90 +- 5.05 (77.96, 69.11, 73.26, 79.23, 64.11, 74.06, 67.53, 69.99, 63.26, 70.48)\n",
      "bias (c0) : 71.29 +- 5.07 (78.25, 69.17, 73.46, 80.05, 65.04, 74.24, 67.66, 70.27, 63.52, 71.22)\n",
      "bias (c1) : 70.51 +- 5.05 (77.67, 69.05, 73.05, 78.40, 63.18, 73.88, 67.40, 69.72, 63.00, 69.74)\n",
      "appearance (all): 29.10 +- 5.05 (22.04, 30.89, 26.74, 20.77, 35.89, 25.94, 32.47, 30.01, 36.74, 29.52)\n",
      "appearance (c0) : 28.71 +- 5.07 (21.75, 30.83, 26.54, 19.95, 34.96, 25.76, 32.34, 29.73, 36.48, 28.78)\n",
      "appearance (c1) : 29.49 +- 5.05 (22.33, 30.95, 26.95, 21.60, 36.82, 26.12, 32.60, 30.28, 37.00, 30.26)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robert-jan/miniconda3/envs/vit/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/robert-jan/miniconda3/envs/vit/lib/python3.10/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/robert-jan/miniconda3/envs/vit/lib/python3.10/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/robert-jan/miniconda3/envs/vit/lib/python3.10/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/home/robert-jan/miniconda3/envs/vit/lib/python3.10/site-packages/numpy/core/_methods.py:257: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[TriViTal(\n",
       "   (patch_layer): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "   (block1): Block(\n",
       "     (attention_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn): Mlp(\n",
       "       (fc1): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (fc2): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "     (attn): Attention(\n",
       "       (query): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (key): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (value): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (out): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (proj_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "     )\n",
       "   )\n",
       "   (pool): AdaptiveAvgPool1d(output_size=[1])\n",
       "   (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "   (fc): Linear(in_features=1, out_features=2, bias=True)\n",
       " ),\n",
       " TriViTal(\n",
       "   (patch_layer): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "   (block1): Block(\n",
       "     (attention_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn): Mlp(\n",
       "       (fc1): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (fc2): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "     (attn): Attention(\n",
       "       (query): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (key): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (value): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (out): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (proj_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "     )\n",
       "   )\n",
       "   (pool): AdaptiveAvgPool1d(output_size=[1])\n",
       "   (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "   (fc): Linear(in_features=1, out_features=2, bias=True)\n",
       " ),\n",
       " TriViTal(\n",
       "   (patch_layer): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "   (block1): Block(\n",
       "     (attention_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn): Mlp(\n",
       "       (fc1): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (fc2): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "     (attn): Attention(\n",
       "       (query): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (key): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (value): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (out): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (proj_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "     )\n",
       "   )\n",
       "   (pool): AdaptiveAvgPool1d(output_size=[1])\n",
       "   (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "   (fc): Linear(in_features=1, out_features=2, bias=True)\n",
       " ),\n",
       " TriViTal(\n",
       "   (patch_layer): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "   (block1): Block(\n",
       "     (attention_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn): Mlp(\n",
       "       (fc1): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (fc2): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "     (attn): Attention(\n",
       "       (query): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (key): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (value): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (out): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (proj_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "     )\n",
       "   )\n",
       "   (pool): AdaptiveAvgPool1d(output_size=[1])\n",
       "   (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "   (fc): Linear(in_features=1, out_features=2, bias=True)\n",
       " ),\n",
       " TriViTal(\n",
       "   (patch_layer): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "   (block1): Block(\n",
       "     (attention_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn): Mlp(\n",
       "       (fc1): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (fc2): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "     (attn): Attention(\n",
       "       (query): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (key): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (value): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (out): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (proj_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "     )\n",
       "   )\n",
       "   (pool): AdaptiveAvgPool1d(output_size=[1])\n",
       "   (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "   (fc): Linear(in_features=1, out_features=2, bias=True)\n",
       " ),\n",
       " TriViTal(\n",
       "   (patch_layer): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "   (block1): Block(\n",
       "     (attention_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn): Mlp(\n",
       "       (fc1): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (fc2): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "     (attn): Attention(\n",
       "       (query): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (key): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (value): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (out): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (proj_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "     )\n",
       "   )\n",
       "   (pool): AdaptiveAvgPool1d(output_size=[1])\n",
       "   (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "   (fc): Linear(in_features=1, out_features=2, bias=True)\n",
       " ),\n",
       " TriViTal(\n",
       "   (patch_layer): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "   (block1): Block(\n",
       "     (attention_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn): Mlp(\n",
       "       (fc1): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (fc2): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "     (attn): Attention(\n",
       "       (query): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (key): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (value): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (out): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (proj_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "     )\n",
       "   )\n",
       "   (pool): AdaptiveAvgPool1d(output_size=[1])\n",
       "   (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "   (fc): Linear(in_features=1, out_features=2, bias=True)\n",
       " ),\n",
       " TriViTal(\n",
       "   (patch_layer): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "   (block1): Block(\n",
       "     (attention_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn): Mlp(\n",
       "       (fc1): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (fc2): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "     (attn): Attention(\n",
       "       (query): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (key): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (value): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (out): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (proj_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "     )\n",
       "   )\n",
       "   (pool): AdaptiveAvgPool1d(output_size=[1])\n",
       "   (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "   (fc): Linear(in_features=1, out_features=2, bias=True)\n",
       " ),\n",
       " TriViTal(\n",
       "   (patch_layer): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "   (block1): Block(\n",
       "     (attention_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn): Mlp(\n",
       "       (fc1): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (fc2): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "     (attn): Attention(\n",
       "       (query): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (key): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (value): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (out): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (proj_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "     )\n",
       "   )\n",
       "   (pool): AdaptiveAvgPool1d(output_size=[1])\n",
       "   (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "   (fc): Linear(in_features=1, out_features=2, bias=True)\n",
       " ),\n",
       " TriViTal(\n",
       "   (patch_layer): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "   (block1): Block(\n",
       "     (attention_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn): Mlp(\n",
       "       (fc1): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (fc2): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "     (attn): Attention(\n",
       "       (query): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (key): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (value): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (out): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (proj_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "     )\n",
       "   )\n",
       "   (pool): AdaptiveAvgPool1d(output_size=[1])\n",
       "   (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "   (fc): Linear(in_features=1, out_features=2, bias=True)\n",
       " )]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%autoreload\n",
    "\n",
    "# Train / hybrid\n",
    "seeds = range(10)\n",
    "n_epochs = 4000\n",
    "report_every_n = 2000\n",
    "lr = 4e-3\n",
    "d = 1\n",
    "n_classes = 2\n",
    "pos_emb = 'none'\n",
    "use_rel_pos = False\n",
    "\n",
    "# DEBUG\n",
    "# seeds = range(2)\n",
    "# n_epochs = 1000\n",
    "# pos_emb = 'none'\n",
    "# use_rel_pos = False\n",
    "\n",
    "run_appearance(seeds, n_epochs, lr, d, n_classes, pos_emb, use_rel_pos, train_images, train_labels, test_images, test_labels, analysis_images, analysis_labels, report_every_n=report_every_n, attribution_method='input_gradient_withnegative')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No PE - with negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 0.7221721410751343\n",
      "Epoch 2000: 0.020952610298991203\n",
      "Epoch 3999: 0.0028742330614477396\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.7209873199462891\n",
      "Epoch 2000: 0.020705854520201683\n",
      "Epoch 3999: 0.002841782057657838\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.7216449975967407\n",
      "Epoch 2000: 0.02286934293806553\n",
      "Epoch 3999: 0.00301276333630085\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 1.0298912525177002\n",
      "Epoch 2000: 0.03404203802347183\n",
      "Epoch 3999: 0.004046170972287655\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.7440201640129089\n",
      "Epoch 2000: 0.024118997156620026\n",
      "Epoch 3999: 0.0031348750926554203\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.9656798839569092\n",
      "Epoch 2000: 0.027722420170903206\n",
      "Epoch 3999: 0.0034386622719466686\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.7159914374351501\n",
      "Epoch 2000: 0.02082267589867115\n",
      "Epoch 3999: 0.002857532585039735\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.6986644268035889\n",
      "Epoch 2000: 0.02043575793504715\n",
      "Epoch 3999: 0.0028189581353217363\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.855926513671875\n",
      "Epoch 2000: 0.0253989789634943\n",
      "Epoch 3999: 0.0032788943499326706\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.8437578082084656\n",
      "Epoch 2000: 0.030298694968223572\n",
      "Epoch 3999: 0.003544479375705123\n",
      "Accuracy: 1.0\n",
      "\n",
      "Without bias:\n",
      "appearance (all): 100.00 +- 0.00 (100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00)\n",
      "appearance (c0) : 100.00 +- 0.00 (100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00)\n",
      "appearance (c1) : 100.00 +- 0.00 (100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00)\n",
      "\n",
      "With bias:\n",
      "bias (all): 76.02 +- 4.41 (82.18, 74.67, 78.60, 82.87, 70.03, 78.57, 73.52, 75.52, 68.79, 75.42)\n",
      "bias (c0) : 76.39 +- 4.48 (82.52, 74.74, 78.75, 83.78, 70.88, 78.72, 73.70, 75.87, 68.87, 76.09)\n",
      "bias (c1) : 75.64 +- 4.37 (81.84, 74.60, 78.44, 81.95, 69.17, 78.42, 73.34, 75.18, 68.70, 74.74)\n",
      "appearance (all): 23.98 +- 4.41 (17.82, 25.33, 21.40, 17.13, 29.97, 21.43, 26.48, 24.48, 31.21, 24.58)\n",
      "appearance (c0) : 23.61 +- 4.48 (17.48, 25.26, 21.25, 16.22, 29.12, 21.28, 26.30, 24.13, 31.13, 23.91)\n",
      "appearance (c1) : 24.36 +- 4.37 (18.16, 25.40, 21.56, 18.05, 30.83, 21.58, 26.66, 24.82, 31.30, 25.26)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robert-jan/miniconda3/envs/vit/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/robert-jan/miniconda3/envs/vit/lib/python3.10/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/robert-jan/miniconda3/envs/vit/lib/python3.10/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/robert-jan/miniconda3/envs/vit/lib/python3.10/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/home/robert-jan/miniconda3/envs/vit/lib/python3.10/site-packages/numpy/core/_methods.py:257: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "# Train / hybrid\n",
    "seeds = range(10)\n",
    "n_epochs = 4000\n",
    "report_every_n = 2000\n",
    "lr = 4e-3\n",
    "d = 1\n",
    "n_classes = 2\n",
    "pos_emb = 'none'\n",
    "use_rel_pos = False\n",
    "\n",
    "# DEBUG\n",
    "# seeds = range(2)\n",
    "# n_epochs = 1000\n",
    "# pos_emb = 'none'\n",
    "# use_rel_pos = False\n",
    "\n",
    "run_appearance(seeds, n_epochs, lr, d, n_classes, pos_emb, use_rel_pos, train_images, train_labels, test_images, test_labels, analysis_images, analysis_labels, report_every_n=report_every_n, attribution_method='input_gradient_withnegative')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 0.7221722602844238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2000: 0.0209524966776371\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.7209873199462891\n",
      "Epoch 2000: 0.02070573717355728\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.7216449975967407\n",
      "Epoch 2000: 0.022870423272252083\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 1.0298912525177002\n",
      "Epoch 2000: 0.034043122082948685\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.7440201640129089\n",
      "Epoch 2000: 0.024119405075907707\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.9656800627708435\n",
      "Epoch 2000: 0.0277236457914114\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.7159914374351501\n",
      "Epoch 2000: 0.02082194574177265\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.6986644268035889\n",
      "Epoch 2000: 0.02043817564845085\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.855926513671875\n",
      "Epoch 2000: 0.02539939247071743\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.8437576293945312\n",
      "Epoch 2000: 0.030304046347737312\n",
      "Accuracy: 1.0\n",
      "\n",
      "Without bias:\n",
      "appearance (all): 100.00 +- 0.00 (100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00)\n",
      "appearance (c0) : 100.00 +- 0.00 (100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00)\n",
      "appearance (c1) : 100.00 +- 0.00 (100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00)\n",
      "\n",
      "With bias:\n",
      "bias (all): 61.39 +- 5.55 (69.70, 59.20, 64.89, 69.71, 55.55, 64.83, 58.17, 60.88, 51.83, 59.17)\n",
      "bias (c0) : 62.09 +- 5.81 (70.27, 59.21, 65.51, 71.84, 57.06, 65.13, 58.47, 61.71, 51.98, 59.75)\n",
      "bias (c1) : 60.70 +- 5.36 (69.14, 59.18, 64.28, 67.59, 54.05, 64.53, 57.88, 60.05, 51.68, 58.59)\n",
      "appearance (all): 38.61 +- 5.55 (30.30, 40.80, 35.11, 30.29, 44.45, 35.17, 41.83, 39.12, 48.17, 40.83)\n",
      "appearance (c0) : 37.91 +- 5.81 (29.73, 40.79, 34.49, 28.16, 42.94, 34.87, 41.53, 38.29, 48.02, 40.25)\n",
      "appearance (c1) : 39.30 +- 5.36 (30.86, 40.82, 35.72, 32.41, 45.95, 35.47, 42.12, 39.95, 48.32, 41.41)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robert-jan/miniconda3/envs/vit/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/robert-jan/miniconda3/envs/vit/lib/python3.10/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/robert-jan/miniconda3/envs/vit/lib/python3.10/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/robert-jan/miniconda3/envs/vit/lib/python3.10/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/home/robert-jan/miniconda3/envs/vit/lib/python3.10/site-packages/numpy/core/_methods.py:257: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "# Train / hybrid\n",
    "seeds = range(10)\n",
    "n_epochs = 4000\n",
    "report_every_n = 2000\n",
    "lr = 4e-3\n",
    "d = 1\n",
    "n_classes = 2\n",
    "pos_emb = 'none'\n",
    "use_rel_pos = False\n",
    "\n",
    "# DEBUG\n",
    "# seeds = range(2)\n",
    "# n_epochs = 1000\n",
    "# pos_emb = 'none'\n",
    "# use_rel_pos = False\n",
    "\n",
    "run_appearance(seeds, n_epochs, lr, d, n_classes, pos_emb, use_rel_pos, train_images, train_labels, test_images, test_labels, analysis_images, analysis_labels, report_every_n=report_every_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APE - fix zero grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 0.6926138997077942\n",
      "Epoch 2000: 0.020731210708618164\n",
      "Epoch 3999: 0.0028638076037168503\n",
      "Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robert-jan/surfdrive/experiments/vit-position-info/toy-experiments/../analysis/learned_relative_position.py:170: RuntimeWarning: Mean of empty slice.\n",
      "  return sf.mean()\n",
      "/home/robert-jan/miniconda3/envs/vit/lib/python3.10/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 0.7174707055091858\n",
      "Epoch 2000: 0.02154436893761158\n",
      "Epoch 3999: 0.002951663685962558\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.7090640068054199\n",
      "Epoch 2000: 0.02065981924533844\n",
      "Epoch 3999: 0.002849587006494403\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.8727425932884216\n",
      "Epoch 2000: 0.030195966362953186\n",
      "Epoch 3999: 0.0036527442280203104\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.755929708480835\n",
      "Epoch 2000: 0.027205418795347214\n",
      "Epoch 3999: 0.003416389226913452\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.7783785462379456\n",
      "Epoch 2000: 0.021834706887602806\n",
      "Epoch 3999: 0.0029628619085997343\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.7028245329856873\n",
      "Epoch 2000: 0.020998334512114525\n",
      "Epoch 3999: 0.0028747646138072014\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.714673638343811\n",
      "Epoch 2000: 0.021592235192656517\n",
      "Epoch 3999: 0.0029047438874840736\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.7572290897369385\n",
      "Epoch 2000: 0.026167424395680428\n",
      "Epoch 3999: 0.003344058059155941\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.8033183217048645\n",
      "Epoch 2000: 0.02244761772453785\n",
      "Epoch 3999: 0.00301438570022583\n",
      "Accuracy: 1.0\n",
      "\n",
      "Without bias:\n",
      "appearance (all): 80.42 +- 5.06 (78.57, 79.13, 87.42, 77.43, 68.97, 84.12, 85.50, 83.73, 77.40, 81.91)\n",
      "appearance (c0) : 80.28 +- 5.08 (78.37, 79.05, 87.41, 77.17, 68.95, 84.06, 85.41, 83.52, 77.03, 81.82)\n",
      "appearance (c1) : 80.56 +- 5.04 (78.76, 79.21, 87.43, 77.69, 68.99, 84.18, 85.59, 83.94, 77.77, 82.00)\n",
      "position (all): 19.58 +- 5.06 (21.43, 20.87, 12.58, 22.57, 31.03, 15.88, 14.50, 16.27, 22.60, 18.09)\n",
      "position (c0) : 19.72 +- 5.08 (21.63, 20.95, 12.59, 22.83, 31.05, 15.94, 14.59, 16.48, 22.97, 18.18)\n",
      "position (c1) : 19.44 +- 5.04 (21.24, 20.79, 12.57, 22.31, 31.01, 15.82, 14.41, 16.06, 22.23, 18.00)\n",
      "\n",
      "With bias:\n",
      "bias (all): 62.22 +- 10.55 (70.63, 71.81, 59.04, 71.75, 67.11, 64.65, 37.70, 51.64, 71.04, 56.83)\n",
      "bias (c0) : 63.05 +- 9.96 (70.91, 71.88, 59.36, 71.94, 67.63, 65.18, 39.83, 53.40, 71.98, 58.36)\n",
      "bias (c1) : 61.39 +- 11.15 (70.34, 71.74, 58.72, 71.56, 66.58, 64.12, 35.58, 49.87, 70.11, 55.30)\n",
      "appearance (all): 30.70 +- 9.97 (23.08, 22.31, 35.81, 21.87, 22.69, 29.74, 53.27, 40.50, 22.42, 35.36)\n",
      "appearance (c0) : 29.99 +- 9.46 (22.80, 22.28, 35.52, 21.66, 22.33, 29.31, 51.40, 38.92, 21.58, 34.07)\n",
      "appearance (c1) : 31.42 +- 10.48 (23.36, 22.34, 36.09, 22.09, 23.04, 30.16, 55.14, 42.08, 23.25, 36.66)\n",
      "position (all): 7.08 +- 1.53 (6.29, 5.88, 5.15, 6.37, 10.21, 5.61, 9.03, 7.86, 6.54, 7.81)\n",
      "position (c0) : 6.97 +- 1.46 (6.29, 5.85, 5.12, 6.41, 10.04, 5.51, 8.78, 7.68, 6.44, 7.57)\n",
      "position (c1) : 7.19 +- 1.60 (6.30, 5.92, 5.19, 6.34, 10.37, 5.72, 9.28, 8.05, 6.64, 8.05)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robert-jan/miniconda3/envs/vit/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/robert-jan/miniconda3/envs/vit/lib/python3.10/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/robert-jan/miniconda3/envs/vit/lib/python3.10/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/home/robert-jan/miniconda3/envs/vit/lib/python3.10/site-packages/numpy/core/_methods.py:257: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[TriViTal(\n",
       "   (patch_layer): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "   (block1): Block(\n",
       "     (attention_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn): Mlp(\n",
       "       (fc1): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (fc2): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "     (attn): Attention(\n",
       "       (query): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (key): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (value): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (out): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (proj_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "     )\n",
       "   )\n",
       "   (pool): AdaptiveAvgPool1d(output_size=[1])\n",
       "   (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "   (fc): Linear(in_features=1, out_features=2, bias=True)\n",
       " ),\n",
       " TriViTal(\n",
       "   (patch_layer): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "   (block1): Block(\n",
       "     (attention_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn): Mlp(\n",
       "       (fc1): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (fc2): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "     (attn): Attention(\n",
       "       (query): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (key): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (value): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (out): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (proj_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "     )\n",
       "   )\n",
       "   (pool): AdaptiveAvgPool1d(output_size=[1])\n",
       "   (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "   (fc): Linear(in_features=1, out_features=2, bias=True)\n",
       " ),\n",
       " TriViTal(\n",
       "   (patch_layer): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "   (block1): Block(\n",
       "     (attention_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn): Mlp(\n",
       "       (fc1): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (fc2): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "     (attn): Attention(\n",
       "       (query): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (key): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (value): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (out): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (proj_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "     )\n",
       "   )\n",
       "   (pool): AdaptiveAvgPool1d(output_size=[1])\n",
       "   (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "   (fc): Linear(in_features=1, out_features=2, bias=True)\n",
       " ),\n",
       " TriViTal(\n",
       "   (patch_layer): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "   (block1): Block(\n",
       "     (attention_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn): Mlp(\n",
       "       (fc1): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (fc2): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "     (attn): Attention(\n",
       "       (query): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (key): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (value): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (out): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (proj_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "     )\n",
       "   )\n",
       "   (pool): AdaptiveAvgPool1d(output_size=[1])\n",
       "   (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "   (fc): Linear(in_features=1, out_features=2, bias=True)\n",
       " ),\n",
       " TriViTal(\n",
       "   (patch_layer): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "   (block1): Block(\n",
       "     (attention_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn): Mlp(\n",
       "       (fc1): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (fc2): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "     (attn): Attention(\n",
       "       (query): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (key): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (value): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (out): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (proj_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "     )\n",
       "   )\n",
       "   (pool): AdaptiveAvgPool1d(output_size=[1])\n",
       "   (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "   (fc): Linear(in_features=1, out_features=2, bias=True)\n",
       " ),\n",
       " TriViTal(\n",
       "   (patch_layer): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "   (block1): Block(\n",
       "     (attention_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn): Mlp(\n",
       "       (fc1): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (fc2): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "     (attn): Attention(\n",
       "       (query): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (key): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (value): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (out): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (proj_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "     )\n",
       "   )\n",
       "   (pool): AdaptiveAvgPool1d(output_size=[1])\n",
       "   (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "   (fc): Linear(in_features=1, out_features=2, bias=True)\n",
       " ),\n",
       " TriViTal(\n",
       "   (patch_layer): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "   (block1): Block(\n",
       "     (attention_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn): Mlp(\n",
       "       (fc1): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (fc2): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "     (attn): Attention(\n",
       "       (query): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (key): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (value): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (out): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (proj_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "     )\n",
       "   )\n",
       "   (pool): AdaptiveAvgPool1d(output_size=[1])\n",
       "   (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "   (fc): Linear(in_features=1, out_features=2, bias=True)\n",
       " ),\n",
       " TriViTal(\n",
       "   (patch_layer): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "   (block1): Block(\n",
       "     (attention_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn): Mlp(\n",
       "       (fc1): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (fc2): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "     (attn): Attention(\n",
       "       (query): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (key): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (value): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (out): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (proj_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "     )\n",
       "   )\n",
       "   (pool): AdaptiveAvgPool1d(output_size=[1])\n",
       "   (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "   (fc): Linear(in_features=1, out_features=2, bias=True)\n",
       " ),\n",
       " TriViTal(\n",
       "   (patch_layer): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "   (block1): Block(\n",
       "     (attention_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn): Mlp(\n",
       "       (fc1): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (fc2): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "     (attn): Attention(\n",
       "       (query): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (key): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (value): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (out): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (proj_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "     )\n",
       "   )\n",
       "   (pool): AdaptiveAvgPool1d(output_size=[1])\n",
       "   (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "   (fc): Linear(in_features=1, out_features=2, bias=True)\n",
       " ),\n",
       " TriViTal(\n",
       "   (patch_layer): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "   (block1): Block(\n",
       "     (attention_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn): Mlp(\n",
       "       (fc1): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (fc2): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "     (attn): Attention(\n",
       "       (query): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (key): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (value): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (out): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (proj_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "     )\n",
       "   )\n",
       "   (pool): AdaptiveAvgPool1d(output_size=[1])\n",
       "   (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "   (fc): Linear(in_features=1, out_features=2, bias=True)\n",
       " )]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%autoreload\n",
    "\n",
    "# Train / hybrid\n",
    "seeds = range(10)\n",
    "n_epochs = 4000\n",
    "report_every_n = 2000\n",
    "lr = 4e-3\n",
    "d = 1\n",
    "n_classes = 2\n",
    "pos_emb = 'absolute'\n",
    "use_rel_pos = False\n",
    "\n",
    "run_appearance(seeds, n_epochs, lr, d, n_classes, pos_emb, use_rel_pos, train_images, train_labels, test_images, test_labels, analysis_images, analysis_labels, report_every_n=report_every_n, attribution_method='input_gradient_withnegative')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APE with negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 0.6926035284996033\n",
      "Epoch 2000: 0.020604902878403664\n",
      "Epoch 3999: 0.002842067740857601\n",
      "Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robert-jan/surfdrive/experiments/vit-position-info/toy-experiments/../analysis/learned_relative_position.py:170: RuntimeWarning: Mean of empty slice.\n",
      "  return sf.mean()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 0.7175094485282898\n",
      "Epoch 2000: 0.021411597728729248\n",
      "Epoch 3999: 0.0029293906409293413\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.7090679407119751\n",
      "Epoch 2000: 0.02053200639784336\n",
      "Epoch 3999: 0.0028276669327169657\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.8722123503684998\n",
      "Epoch 2000: 0.029946614056825638\n",
      "Epoch 3999: 0.0036165472120046616\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.7557835578918457\n",
      "Epoch 2000: 0.027009902521967888\n",
      "Epoch 3999: 0.003388101700693369\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.7782129645347595\n",
      "Epoch 2000: 0.021694261580705643\n",
      "Epoch 3999: 0.0029401599895209074\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.7029451131820679\n",
      "Epoch 2000: 0.020871955901384354\n",
      "Epoch 3999: 0.002853160258382559\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.7146598696708679\n",
      "Epoch 2000: 0.021454351022839546\n",
      "Epoch 3999: 0.002882399596273899\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.7567547559738159\n",
      "Epoch 2000: 0.02598174847662449\n",
      "Epoch 3999: 0.003316637594252825\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.8032578825950623\n",
      "Epoch 2000: 0.02230069600045681\n",
      "Epoch 3999: 0.002991217654198408\n",
      "Accuracy: 1.0\n",
      "\n",
      "Without bias:\n",
      "appearance (all): 76.16 +- 5.74 (71.79, 74.25, 85.51, 73.99, 64.33, 78.86, 81.42, 80.69, 72.33, 78.39)\n",
      "appearance (c0) : 75.40 +- 5.85 (72.47, 73.81, 84.08, 71.72, 63.06, 79.92, 81.06, 79.34, 71.14, 77.41)\n",
      "appearance (c1) : 75.82 +- 5.76 (73.17, 73.97, 84.09, 72.64, 63.09, 80.00, 81.30, 79.94, 72.33, 77.70)\n",
      "position (all): 23.84 +- 5.74 (28.21, 25.75, 14.49, 26.01, 35.67, 21.14, 18.58, 19.31, 27.67, 21.61)\n",
      "position (c0) : 24.60 +- 5.85 (27.53, 26.19, 15.92, 28.28, 36.94, 20.08, 18.94, 20.66, 28.86, 22.59)\n",
      "position (c1) : 24.18 +- 5.76 (26.83, 26.03, 15.91, 27.36, 36.91, 20.00, 18.70, 20.06, 27.67, 22.30)\n",
      "\n",
      "With bias:\n",
      "bias (all): 67.11 +- 9.97 (74.68, 76.03, 65.06, 76.27, 71.55, 69.34, 43.54, 57.34, 75.34, 61.99)\n",
      "bias (c0) : 67.80 +- 9.38 (75.27, 76.02, 64.95, 76.09, 71.64, 70.16, 45.69, 58.83, 76.13, 63.27)\n",
      "bias (c1) : 66.12 +- 10.62 (74.63, 75.87, 64.40, 75.56, 70.66, 69.11, 41.25, 55.21, 74.26, 60.21)\n",
      "appearance (all): 25.39 +- 9.08 (18.18, 17.79, 29.88, 17.56, 18.29, 24.18, 45.98, 34.44, 17.83, 29.79)\n",
      "appearance (c0) : 24.62 +- 8.55 (17.92, 17.74, 29.47, 17.15, 17.89, 23.87, 44.03, 32.67, 16.99, 28.43)\n",
      "appearance (c1) : 26.03 +- 9.55 (18.56, 17.81, 29.93, 17.75, 18.50, 24.69, 47.76, 35.80, 18.61, 30.92)\n",
      "position (all): 7.49 +- 1.68 (7.14, 6.17, 5.06, 6.18, 10.16, 6.48, 10.48, 8.22, 6.82, 8.23)\n",
      "position (c0) : 7.58 +- 1.65 (6.81, 6.24, 5.57, 6.76, 10.47, 5.97, 10.29, 8.51, 6.89, 8.30)\n",
      "position (c1) : 7.85 +- 1.84 (6.81, 6.32, 5.67, 6.69, 10.84, 6.20, 10.98, 8.98, 7.12, 8.87)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train / hybrid\n",
    "seeds = range(10)\n",
    "n_epochs = 4000\n",
    "report_every_n = 2000\n",
    "lr = 4e-3\n",
    "d = 1\n",
    "n_classes = 2\n",
    "pos_emb = 'absolute'\n",
    "use_rel_pos = False\n",
    "\n",
    "run_appearance(seeds, n_epochs, lr, d, n_classes, pos_emb, use_rel_pos, train_images, train_labels, test_images, test_labels, analysis_images, analysis_labels, report_every_n=report_every_n, attribution_method='input_gradient_withnegative')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 0.692603588104248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2000: 0.020604804158210754\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.7175095081329346\n",
      "Epoch 2000: 0.0214115921407938\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.7090680003166199\n",
      "Epoch 2000: 0.020531801506876945\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.872212290763855\n",
      "Epoch 2000: 0.02994842268526554\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.7557835578918457\n",
      "Epoch 2000: 0.02700888365507126\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.7782129645347595\n",
      "Epoch 2000: 0.021694589406251907\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.7029451131820679\n",
      "Epoch 2000: 0.020871929824352264\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.7146598100662231\n",
      "Epoch 2000: 0.0214548259973526\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.7567547559738159\n",
      "Epoch 2000: 0.025981731712818146\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.8032580614089966\n",
      "Epoch 2000: 0.02230077236890793\n",
      "Accuracy: 1.0\n",
      "\n",
      "Without bias:\n",
      "appearance (all): 84.03 +- 9.16 (72.98, 78.25, 94.72, 74.15, 99.88, 82.92, 84.33, 93.05, 72.76, 87.27)\n",
      "appearance (c0) : 78.86 +- 7.80 (74.32, 77.86, 88.73, 71.88, 63.13, 83.83, 84.02, 85.28, 72.75, 86.82)\n",
      "appearance (c1) : 95.50 +- 3.59 (97.80, 93.46, 94.15, 99.73, 99.88, 94.53, 95.90, 92.50, 99.11, 87.92)\n",
      "position (all): 15.97 +- 9.16 (27.02, 21.75, 5.28, 25.85, 0.12, 17.08, 15.67, 6.95, 27.24, 12.73)\n",
      "position (c0) : 21.14 +- 7.80 (25.68, 22.14, 11.27, 28.12, 36.87, 16.17, 15.98, 14.72, 27.25, 13.18)\n",
      "position (c1) : 4.50 +- 3.59 (2.20, 6.54, 5.85, 0.27, 0.12, 5.47, 4.10, 7.50, 0.89, 12.08)\n",
      "\n",
      "With bias:\n",
      "bias (all): 53.57 +- 10.17 (59.80, 62.36, 51.38, 60.89, 66.19, 55.62, 31.99, 42.13, 59.65, 45.66)\n",
      "bias (c0) : 56.86 +- 12.22 (68.68, 61.09, 52.31, 59.88, 71.76, 60.66, 30.99, 44.91, 70.28, 48.05)\n",
      "bias (c1) : 51.76 +- 10.61 (57.97, 67.53, 48.67, 67.96, 49.31, 54.00, 35.80, 37.15, 55.84, 43.33)\n",
      "appearance (all): 39.24 +- 10.43 (29.36, 29.45, 46.06, 28.97, 33.77, 36.82, 57.35, 53.86, 29.36, 47.41)\n",
      "appearance (c0) : 38.41 +- 10.19 (30.63, 30.30, 44.90, 28.84, 28.21, 37.19, 57.98, 50.95, 29.45, 45.68)\n",
      "appearance (c1) : 40.61 +- 10.61 (31.24, 30.34, 45.54, 31.95, 32.00, 38.56, 61.57, 53.60, 32.13, 49.20)\n",
      "position (all): 7.19 +- 3.64 (10.84, 8.19, 2.56, 10.13, 0.04, 7.57, 10.66, 4.00, 10.99, 6.93)\n",
      "position (c0) : 4.73 +- 4.11 (0.69, 8.61, 2.79, 11.28, 0.04, 2.15, 11.03, 4.13, 0.26, 6.27)\n",
      "position (c1) : 7.63 +- 5.20 (10.79, 2.12, 5.78, 0.09, 18.69, 7.44, 2.63, 9.26, 12.03, 7.47)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train / hybrid\n",
    "seeds = range(10)\n",
    "n_epochs = 4000\n",
    "report_every_n = 2000\n",
    "lr = 4e-3\n",
    "d = 1\n",
    "n_classes = 2\n",
    "pos_emb = 'absolute'\n",
    "use_rel_pos = False\n",
    "\n",
    "run_appearance(seeds, n_epochs, lr, d, n_classes, pos_emb, use_rel_pos, train_images, train_labels, test_images, test_labels, analysis_images, analysis_labels, report_every_n=report_every_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RPE - fix zero grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 0.6926027536392212\n",
      "Epoch 2000: 0.0207512266933918\n",
      "Epoch 3999: 0.002866663271561265\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.9278618097305298\n",
      "Epoch 2000: 0.0248568058013916\n",
      "Epoch 3999: 0.003245915984734893\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 1.2104240655899048\n",
      "Epoch 2000: 0.037657011300325394\n",
      "Epoch 3999: 0.0043170396238565445\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.6976462006568909\n",
      "Epoch 2000: 0.02112886868417263\n",
      "Epoch 3999: 0.002885199850425124\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.7913115620613098\n",
      "Epoch 2000: 0.02754129096865654\n",
      "Epoch 3999: 0.0034546973183751106\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.7128941416740417\n",
      "Epoch 2000: 0.02140103094279766\n",
      "Epoch 3999: 0.002879682695493102\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.7117297649383545\n",
      "Epoch 2000: 0.020817551761865616\n",
      "Epoch 3999: 0.0028600646182894707\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.7011004090309143\n",
      "Epoch 2000: 0.020352354273200035\n",
      "Epoch 3999: 0.002792718820273876\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.7098996043205261\n",
      "Epoch 2000: 0.021050434559583664\n",
      "Epoch 3999: 0.0028810626827180386\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 1.1478917598724365\n",
      "Epoch 2000: 0.04261269420385361\n",
      "Epoch 3999: 0.004698969889432192\n",
      "Accuracy: 1.0\n",
      "\n",
      "Without bias:\n",
      "appearance (all): 100.00 +- 0.00 (100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00)\n",
      "appearance (c0) : 100.00 +- 0.00 (100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00)\n",
      "appearance (c1) : 100.00 +- 0.00 (100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00)\n",
      "relative_position (all): 0.00 +- 0.00 (0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00)\n",
      "relative_position (c0) : 0.00 +- 0.00 (0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00)\n",
      "relative_position (c1) : 0.00 +- 0.00 (0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00)\n",
      "\n",
      "With bias:\n",
      "bias (all): 70.41 +- 5.20 (77.69, 68.10, 71.26, 80.05, 64.56, 74.46, 67.62, 68.66, 63.09, 68.61)\n",
      "bias (c0) : 70.91 +- 5.31 (77.94, 68.19, 72.32, 81.16, 65.06, 74.55, 68.15, 68.93, 63.32, 69.52)\n",
      "bias (c1) : 69.90 +- 5.11 (77.44, 68.01, 70.20, 78.94, 64.05, 74.36, 67.08, 68.39, 62.86, 67.70)\n",
      "appearance (all): 29.59 +- 5.20 (22.31, 31.90, 28.74, 19.95, 35.44, 25.54, 32.38, 31.34, 36.91, 31.39)\n",
      "appearance (c0) : 29.09 +- 5.31 (22.06, 31.81, 27.68, 18.84, 34.94, 25.45, 31.85, 31.07, 36.68, 30.48)\n",
      "appearance (c1) : 30.10 +- 5.11 (22.56, 31.99, 29.80, 21.06, 35.95, 25.64, 32.92, 31.61, 37.14, 32.30)\n",
      "relative_position (all): 0.00 +- 0.00 (0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00)\n",
      "relative_position (c0) : 0.00 +- 0.00 (0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00)\n",
      "relative_position (c1) : 0.00 +- 0.00 (0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[TriViTal(\n",
       "   (patch_layer): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "   (block1): Block(\n",
       "     (attention_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn): Mlp(\n",
       "       (fc1): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (fc2): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "     (attn): Attention(\n",
       "       (query): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (key): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (value): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (out): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (proj_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "       (rel_pos): RelPosEmb2D(\n",
       "         (emb_w): RelPosEmb1D()\n",
       "         (emb_h): RelPosEmb1D()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (pool): AdaptiveAvgPool1d(output_size=[1])\n",
       "   (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "   (fc): Linear(in_features=1, out_features=2, bias=True)\n",
       " ),\n",
       " TriViTal(\n",
       "   (patch_layer): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "   (block1): Block(\n",
       "     (attention_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn): Mlp(\n",
       "       (fc1): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (fc2): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "     (attn): Attention(\n",
       "       (query): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (key): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (value): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (out): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (proj_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "       (rel_pos): RelPosEmb2D(\n",
       "         (emb_w): RelPosEmb1D()\n",
       "         (emb_h): RelPosEmb1D()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (pool): AdaptiveAvgPool1d(output_size=[1])\n",
       "   (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "   (fc): Linear(in_features=1, out_features=2, bias=True)\n",
       " ),\n",
       " TriViTal(\n",
       "   (patch_layer): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "   (block1): Block(\n",
       "     (attention_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn): Mlp(\n",
       "       (fc1): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (fc2): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "     (attn): Attention(\n",
       "       (query): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (key): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (value): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (out): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (proj_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "       (rel_pos): RelPosEmb2D(\n",
       "         (emb_w): RelPosEmb1D()\n",
       "         (emb_h): RelPosEmb1D()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (pool): AdaptiveAvgPool1d(output_size=[1])\n",
       "   (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "   (fc): Linear(in_features=1, out_features=2, bias=True)\n",
       " ),\n",
       " TriViTal(\n",
       "   (patch_layer): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "   (block1): Block(\n",
       "     (attention_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn): Mlp(\n",
       "       (fc1): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (fc2): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "     (attn): Attention(\n",
       "       (query): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (key): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (value): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (out): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (proj_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "       (rel_pos): RelPosEmb2D(\n",
       "         (emb_w): RelPosEmb1D()\n",
       "         (emb_h): RelPosEmb1D()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (pool): AdaptiveAvgPool1d(output_size=[1])\n",
       "   (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "   (fc): Linear(in_features=1, out_features=2, bias=True)\n",
       " ),\n",
       " TriViTal(\n",
       "   (patch_layer): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "   (block1): Block(\n",
       "     (attention_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn): Mlp(\n",
       "       (fc1): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (fc2): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "     (attn): Attention(\n",
       "       (query): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (key): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (value): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (out): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (proj_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "       (rel_pos): RelPosEmb2D(\n",
       "         (emb_w): RelPosEmb1D()\n",
       "         (emb_h): RelPosEmb1D()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (pool): AdaptiveAvgPool1d(output_size=[1])\n",
       "   (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "   (fc): Linear(in_features=1, out_features=2, bias=True)\n",
       " ),\n",
       " TriViTal(\n",
       "   (patch_layer): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "   (block1): Block(\n",
       "     (attention_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn): Mlp(\n",
       "       (fc1): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (fc2): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "     (attn): Attention(\n",
       "       (query): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (key): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (value): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (out): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (proj_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "       (rel_pos): RelPosEmb2D(\n",
       "         (emb_w): RelPosEmb1D()\n",
       "         (emb_h): RelPosEmb1D()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (pool): AdaptiveAvgPool1d(output_size=[1])\n",
       "   (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "   (fc): Linear(in_features=1, out_features=2, bias=True)\n",
       " ),\n",
       " TriViTal(\n",
       "   (patch_layer): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "   (block1): Block(\n",
       "     (attention_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn): Mlp(\n",
       "       (fc1): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (fc2): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "     (attn): Attention(\n",
       "       (query): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (key): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (value): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (out): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (proj_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "       (rel_pos): RelPosEmb2D(\n",
       "         (emb_w): RelPosEmb1D()\n",
       "         (emb_h): RelPosEmb1D()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (pool): AdaptiveAvgPool1d(output_size=[1])\n",
       "   (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "   (fc): Linear(in_features=1, out_features=2, bias=True)\n",
       " ),\n",
       " TriViTal(\n",
       "   (patch_layer): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "   (block1): Block(\n",
       "     (attention_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn): Mlp(\n",
       "       (fc1): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (fc2): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "     (attn): Attention(\n",
       "       (query): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (key): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (value): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (out): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (proj_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "       (rel_pos): RelPosEmb2D(\n",
       "         (emb_w): RelPosEmb1D()\n",
       "         (emb_h): RelPosEmb1D()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (pool): AdaptiveAvgPool1d(output_size=[1])\n",
       "   (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "   (fc): Linear(in_features=1, out_features=2, bias=True)\n",
       " ),\n",
       " TriViTal(\n",
       "   (patch_layer): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "   (block1): Block(\n",
       "     (attention_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn): Mlp(\n",
       "       (fc1): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (fc2): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "     (attn): Attention(\n",
       "       (query): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (key): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (value): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (out): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (proj_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "       (rel_pos): RelPosEmb2D(\n",
       "         (emb_w): RelPosEmb1D()\n",
       "         (emb_h): RelPosEmb1D()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (pool): AdaptiveAvgPool1d(output_size=[1])\n",
       "   (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "   (fc): Linear(in_features=1, out_features=2, bias=True)\n",
       " ),\n",
       " TriViTal(\n",
       "   (patch_layer): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "   (block1): Block(\n",
       "     (attention_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn_norm): LayerNorm((1,), eps=1e-06, elementwise_affine=True)\n",
       "     (ffn): Mlp(\n",
       "       (fc1): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (fc2): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "     (attn): Attention(\n",
       "       (query): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (key): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (value): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (out): Linear(in_features=1, out_features=1, bias=True)\n",
       "       (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (proj_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "       (rel_pos): RelPosEmb2D(\n",
       "         (emb_w): RelPosEmb1D()\n",
       "         (emb_h): RelPosEmb1D()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (pool): AdaptiveAvgPool1d(output_size=[1])\n",
       "   (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "   (fc): Linear(in_features=1, out_features=2, bias=True)\n",
       " )]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%autoreload\n",
    "\n",
    "# Train / hybrid\n",
    "seeds = range(10)\n",
    "n_epochs = 4000\n",
    "report_every_n = 2000\n",
    "lr = 4e-3\n",
    "d = 1\n",
    "n_classes = 2\n",
    "pos_emb = 'none'\n",
    "use_rel_pos = True\n",
    "\n",
    "# DEBUG\n",
    "# n_epochs = 1000\n",
    "\n",
    "run_appearance(seeds, n_epochs, lr, d, n_classes, pos_emb, use_rel_pos, train_images, train_labels, test_images, test_labels, analysis_images, analysis_labels, report_every_n=report_every_n, attribution_method='input_gradient_withnegative')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RPE with negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 0.6925969123840332\n",
      "Epoch 2000: 0.020624229684472084\n",
      "Epoch 3999: 0.0028446349315345287\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.9278261065483093\n",
      "Epoch 2000: 0.02470528893172741\n",
      "Epoch 3999: 0.003221086459234357\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 1.2106820344924927\n",
      "Epoch 2000: 0.037503279745578766\n",
      "Epoch 3999: 0.004287607502192259\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.6974081993103027\n",
      "Epoch 2000: 0.020968405529856682\n",
      "Epoch 3999: 0.002860670443624258\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.7914978861808777\n",
      "Epoch 2000: 0.027357861399650574\n",
      "Epoch 3999: 0.0034279651008546352\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.7127645611763\n",
      "Epoch 2000: 0.02126195840537548\n",
      "Epoch 3999: 0.002857315819710493\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.7118509411811829\n",
      "Epoch 2000: 0.020689690485596657\n",
      "Epoch 3999: 0.0028384774923324585\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.7010971307754517\n",
      "Epoch 2000: 0.020218145102262497\n",
      "Epoch 3999: 0.002770097926259041\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.7099552154541016\n",
      "Epoch 2000: 0.020913492888212204\n",
      "Epoch 3999: 0.0028581267688423395\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 1.1480817794799805\n",
      "Epoch 2000: 0.042374711483716965\n",
      "Epoch 3999: 0.004662867169827223\n",
      "Accuracy: 1.0\n",
      "\n",
      "Without bias:\n",
      "appearance (all): 100.00 +- 0.00 (100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00)\n",
      "appearance (c0) : 100.00 +- 0.00 (100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00)\n",
      "appearance (c1) : 100.00 +- 0.00 (100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00)\n",
      "relative_position (all): 0.00 +- 0.00 (0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00)\n",
      "relative_position (c0) : 0.00 +- 0.00 (0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00)\n",
      "relative_position (c1) : 0.00 +- 0.00 (0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00)\n",
      "\n",
      "With bias:\n",
      "bias (all): 75.63 +- 4.63 (82.15, 73.44, 76.02, 84.16, 70.66, 79.48, 73.21, 74.81, 69.10, 73.26)\n",
      "bias (c0) : 76.11 +- 4.77 (82.44, 73.54, 76.94, 85.31, 71.19, 79.56, 73.70, 75.11, 69.15, 74.14)\n",
      "bias (c1) : 75.15 +- 4.52 (81.86, 73.34, 75.10, 83.00, 70.13, 79.41, 72.72, 74.51, 69.06, 72.38)\n",
      "appearance (all): 24.37 +- 4.63 (17.85, 26.56, 23.98, 15.84, 29.34, 20.52, 26.79, 25.19, 30.90, 26.74)\n",
      "appearance (c0) : 23.89 +- 4.77 (17.56, 26.46, 23.06, 14.69, 28.81, 20.44, 26.30, 24.89, 30.85, 25.86)\n",
      "appearance (c1) : 24.85 +- 4.52 (18.14, 26.66, 24.90, 17.00, 29.87, 20.59, 27.28, 25.49, 30.94, 27.62)\n",
      "relative_position (all): 0.00 +- 0.00 (0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00)\n",
      "relative_position (c0) : 0.00 +- 0.00 (0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00)\n",
      "relative_position (c1) : 0.00 +- 0.00 (0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "\n",
    "# Train / hybrid\n",
    "seeds = range(10)\n",
    "n_epochs = 4000\n",
    "report_every_n = 2000\n",
    "lr = 4e-3\n",
    "d = 1\n",
    "n_classes = 2\n",
    "pos_emb = 'none'\n",
    "use_rel_pos = True\n",
    "\n",
    "# DEBUG\n",
    "# n_epochs = 1000\n",
    "\n",
    "run_appearance(seeds, n_epochs, lr, d, n_classes, pos_emb, use_rel_pos, train_images, train_labels, test_images, test_labels, analysis_images, analysis_labels, report_every_n=report_every_n, attribution_method='input_gradient_withnegative')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 0.6925969123840332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Epoch 0: 0.9278262257575989\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 1.2106820344924927\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.6974083185195923\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.7914978861808777\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.7127646803855896\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.7118510603904724\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.7010972499847412\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.7099552750587463\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 1.1480820178985596\n",
      "Accuracy: 1.0\n",
      "\n",
      "Without bias:\n",
      "appearance (all): 100.00 +- 0.00 (100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00)\n",
      "appearance (c0) : 100.00 +- 0.00 (100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00)\n",
      "appearance (c1) : 100.00 +- 0.00 (100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00, 100.00)\n",
      "relative_position (all): 0.00 +- 0.00 (0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00)\n",
      "relative_position (c0) : 0.00 +- 0.00 (0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00)\n",
      "relative_position (c1) : 0.00 +- 0.00 (0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00)\n",
      "\n",
      "With bias:\n",
      "bias (all): 73.82 +- 5.46 (80.59, 71.45, 77.13, 82.64, 68.82, 76.55, 72.44, 71.23, 63.05, 74.30)\n",
      "bias (c0) : 74.92 +- 5.87 (81.03, 71.77, 78.22, 85.19, 69.73, 76.79, 73.21, 72.06, 63.46, 77.73)\n",
      "bias (c1) : 72.72 +- 5.20 (80.15, 71.14, 76.03, 80.10, 67.90, 76.30, 71.66, 70.40, 62.63, 70.87)\n",
      "appearance (all): 26.18 +- 5.46 (19.41, 28.55, 22.87, 17.36, 31.18, 23.45, 27.56, 28.77, 36.95, 25.70)\n",
      "appearance (c0) : 25.08 +- 5.87 (18.97, 28.23, 21.78, 14.81, 30.27, 23.21, 26.79, 27.94, 36.54, 22.27)\n",
      "appearance (c1) : 27.28 +- 5.20 (19.85, 28.86, 23.97, 19.90, 32.10, 23.70, 28.34, 29.60, 37.37, 29.13)\n",
      "relative_position (all): 0.00 +- 0.00 (0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00)\n",
      "relative_position (c0) : 0.00 +- 0.00 (0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00)\n",
      "relative_position (c1) : 0.00 +- 0.00 (0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "\n",
    "# Train / hybrid\n",
    "seeds = range(10)\n",
    "n_epochs = 4000\n",
    "report_every_n = 2000\n",
    "lr = 4e-3\n",
    "d = 1\n",
    "n_classes = 2\n",
    "pos_emb = 'none'\n",
    "use_rel_pos = True\n",
    "\n",
    "# DEBUG\n",
    "# n_epochs = 1000\n",
    "\n",
    "run_appearance(seeds, n_epochs, lr, d, n_classes, pos_emb, use_rel_pos, train_images, train_labels, test_images, test_labels, analysis_images, analysis_labels, report_every_n=report_every_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APE+RPE - fix zero grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 1.2760506868362427\n",
      "Epoch 2000: 0.03443369269371033\n",
      "Epoch 3999: 0.004104109015315771\n",
      "Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robert-jan/surfdrive/experiments/vit-position-info/toy-experiments/../analysis/learned_relative_position.py:170: RuntimeWarning: Mean of empty slice.\n",
      "  return sf.mean()\n",
      "/home/robert-jan/miniconda3/envs/vit/lib/python3.10/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 0.8980551362037659\n",
      "Epoch 2000: 0.02474125847220421\n",
      "Epoch 3999: 0.003184032626450062\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.7707328796386719\n",
      "Epoch 2000: 0.023742320016026497\n",
      "Epoch 3999: 0.00312598398886621\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.8472079634666443\n",
      "Epoch 2000: 0.029800014570355415\n",
      "Epoch 3999: 0.0036563801113516092\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.7198459506034851\n",
      "Epoch 2000: 0.02296244353055954\n",
      "Epoch 3999: 0.003032037988305092\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.6915395259857178\n",
      "Epoch 2000: 0.021110057830810547\n",
      "Epoch 3999: 0.002914430806413293\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.6995021104812622\n",
      "Epoch 2000: 0.020926324650645256\n",
      "Epoch 3999: 0.0028809222858399153\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.7070560455322266\n",
      "Epoch 2000: 0.02143772877752781\n",
      "Epoch 3999: 0.002940355334430933\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.8615553975105286\n",
      "Epoch 2000: 0.029621915891766548\n",
      "Epoch 3999: 0.0036309233400970697\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.8794817924499512\n",
      "Epoch 2000: 0.027587855234742165\n",
      "Epoch 3999: 0.0034506693482398987\n",
      "Accuracy: 1.0\n",
      "\n",
      "Without bias:\n",
      "appearance (all): 79.79 +- 5.15 (77.03, 78.35, 88.43, 75.69, 70.18, 82.80, 83.95, 82.98, 75.11, 83.43)\n",
      "appearance (c0) : 79.58 +- 5.25 (76.73, 78.13, 88.40, 74.71, 70.16, 82.79, 83.87, 82.81, 74.89, 83.34)\n",
      "appearance (c1) : 80.00 +- 5.06 (77.32, 78.57, 88.46, 76.67, 70.21, 82.80, 84.03, 83.15, 75.32, 83.52)\n",
      "position (all): 20.21 +- 5.15 (22.97, 21.65, 11.57, 24.31, 29.82, 17.20, 16.05, 17.02, 24.89, 16.57)\n",
      "position (c0) : 20.42 +- 5.25 (23.27, 21.87, 11.60, 25.29, 29.84, 17.21, 16.13, 17.19, 25.11, 16.66)\n",
      "position (c1) : 20.00 +- 5.06 (22.68, 21.43, 11.54, 23.33, 29.79, 17.20, 15.97, 16.85, 24.68, 16.48)\n",
      "relative_position (all): 0.00 +- 0.00 (0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00)\n",
      "relative_position (c0) : 0.00 +- 0.00 (0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00)\n",
      "relative_position (c1) : 0.00 +- 0.00 (0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00)\n",
      "\n",
      "With bias:\n",
      "bias (all): 62.75 +- 10.57 (69.43, 71.61, 58.84, 73.04, 68.09, 67.33, 38.49, 56.34, 71.98, 52.31)\n",
      "bias (c0) : 63.41 +- 10.19 (69.44, 71.71, 59.97, 73.86, 68.51, 67.64, 39.62, 57.44, 72.06, 53.86)\n",
      "bias (c1) : 62.08 +- 10.97 (69.43, 71.51, 57.72, 72.22, 67.67, 67.03, 37.36, 55.24, 71.89, 50.77)\n",
      "appearance (all): 30.07 +- 9.92 (23.54, 22.24, 36.40, 20.41, 22.40, 27.05, 51.64, 36.23, 21.05, 39.79)\n",
      "appearance (c0) : 29.48 +- 9.60 (23.45, 22.23, 35.39, 19.53, 22.09, 26.79, 50.65, 35.25, 20.93, 38.54)\n",
      "appearance (c1) : 30.67 +- 10.25 (23.64, 22.26, 37.40, 21.30, 22.70, 27.30, 52.63, 37.22, 21.17, 41.03)\n",
      "position (all): 7.18 +- 1.52 (7.02, 6.15, 4.76, 6.55, 9.51, 5.62, 9.87, 7.43, 6.98, 7.90)\n",
      "position (c0) : 7.11 +- 1.49 (7.11, 6.06, 4.64, 6.61, 9.40, 5.57, 9.74, 7.31, 7.01, 7.60)\n",
      "position (c1) : 7.25 +- 1.56 (6.93, 6.23, 4.88, 6.48, 9.63, 5.67, 10.00, 7.54, 6.94, 8.20)\n",
      "relative_position (all): 0.00 +- 0.00 (0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00)\n",
      "relative_position (c0) : 0.00 +- 0.00 (0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00)\n",
      "relative_position (c1) : 0.00 +- 0.00 (0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robert-jan/miniconda3/envs/vit/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/robert-jan/miniconda3/envs/vit/lib/python3.10/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/robert-jan/miniconda3/envs/vit/lib/python3.10/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/home/robert-jan/miniconda3/envs/vit/lib/python3.10/site-packages/numpy/core/_methods.py:257: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "\n",
    "# Train / hybrid\n",
    "seeds = range(10)\n",
    "n_epochs = 4000\n",
    "report_every_n = 2000\n",
    "lr = 4e-3\n",
    "d = 1\n",
    "n_classes = 2\n",
    "pos_emb = 'absolute'\n",
    "use_rel_pos = True\n",
    "\n",
    "models = run_appearance(seeds, n_epochs, lr, d, n_classes, pos_emb, use_rel_pos, train_images, train_labels, test_images, test_labels, analysis_images, analysis_labels, report_every_n=report_every_n, attribution_method='input_gradient_withnegative')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "from utils import visualize_sensitivities\n",
    "\n",
    "# seed = 1\n",
    "\n",
    "n = len(analysis_images)\n",
    "# n = 10\n",
    "# manual_sort = [\n",
    "#     0, 7, 14, 21, 28,\n",
    "#     2, 9, 16, 23, 30,\n",
    "#     4, 11, 18, 25, 32,\n",
    "#     6, 13, 20, 27, 34,\n",
    "#     1, 8, 15, 22, 29,\n",
    "#     3, 10, 17, 24, 31,\n",
    "#     5, 12, 19, 26, 33,\n",
    "# ]\n",
    "sort = 'appearance'\n",
    "\n",
    "snrs = []\n",
    "for seed in seeds:\n",
    "    snrs.append(visualize_sensitivities(models[seed], seed, analysis_images, analysis_labels, ape=True, rpe=True, sort=sort, n=n, snr_signal='appearance', only_snr=True))\n",
    "\n",
    "snrs = np.array(snrs)\n",
    "print(np.mean(snrs), np.std(snrs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APE+RPE with negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 1.2754610776901245\n",
      "Epoch 2000: 0.03394591063261032\n",
      "Epoch 3999: 0.0040551889687776566\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.8981919288635254\n",
      "Epoch 2000: 0.024572474882006645\n",
      "Epoch 3999: 0.0031591576989740133\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.7707257866859436\n",
      "Epoch 2000: 0.02359362319111824\n",
      "Epoch 3999: 0.0031020354945212603\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.8461413383483887\n",
      "Epoch 2000: 0.029515180736780167\n",
      "Epoch 3999: 0.003620202885940671\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.7197996377944946\n",
      "Epoch 2000: 0.022811483591794968\n",
      "Epoch 3999: 0.0030079949647188187\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.6913833618164062\n",
      "Epoch 2000: 0.020982343703508377\n",
      "Epoch 3999: 0.0028926099184900522\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.6992994546890259\n",
      "Epoch 2000: 0.020786670967936516\n",
      "Epoch 3999: 0.0028578918427228928\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.7071033716201782\n",
      "Epoch 2000: 0.02130769193172455\n",
      "Epoch 3999: 0.0029183775186538696\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.8632459044456482\n",
      "Epoch 2000: 0.02952188439667225\n",
      "Epoch 3999: 0.0036119315773248672\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.879478931427002\n",
      "Epoch 2000: 0.027415962889790535\n",
      "Epoch 3999: 0.0034246176946908236\n",
      "Accuracy: 1.0\n",
      "\n",
      "Without bias:\n",
      "appearance (all): 75.26 +- 5.46 (72.15, 73.24, 84.65, 70.97, 65.47, 78.53, 80.13, 78.63, 70.24, 78.59)\n",
      "appearance (c0) : 74.96 +- 6.08 (72.37, 73.68, 85.25, 69.16, 63.44, 78.15, 79.96, 78.31, 70.01, 79.24)\n",
      "appearance (c1) : 75.53 +- 5.85 (72.96, 74.29, 85.29, 71.80, 63.52, 78.24, 80.25, 78.91, 70.64, 79.43)\n",
      "position (all): 24.74 +- 5.46 (27.85, 26.76, 15.35, 29.03, 34.53, 21.47, 19.87, 21.37, 29.76, 21.41)\n",
      "position (c0) : 25.04 +- 6.08 (27.63, 26.32, 14.75, 30.84, 36.56, 21.84, 20.04, 21.69, 29.99, 20.76)\n",
      "position (c1) : 24.47 +- 5.85 (27.04, 25.71, 14.71, 28.20, 36.48, 21.76, 19.75, 21.09, 29.36, 20.57)\n",
      "relative_position (all): 0.00 +- 0.00 (0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00)\n",
      "relative_position (c0) : 0.00 +- 0.00 (0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00)\n",
      "relative_position (c1) : 0.00 +- 0.00 (0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00)\n",
      "\n",
      "With bias:\n",
      "bias (all): 67.31 +- 9.82 (72.85, 75.13, 64.31, 76.81, 72.46, 72.25, 44.14, 62.19, 75.37, 57.62)\n",
      "bias (c0) : 67.95 +- 9.36 (72.95, 75.26, 65.52, 77.52, 72.21, 72.48, 45.37, 63.32, 75.51, 59.39)\n",
      "bias (c1) : 66.66 +- 10.20 (73.02, 75.38, 63.44, 75.86, 71.49, 71.85, 42.90, 61.04, 75.28, 56.31)\n",
      "appearance (all): 24.94 +- 8.81 (19.59, 18.21, 30.21, 16.47, 18.02, 21.79, 44.76, 29.74, 17.30, 33.32)\n",
      "appearance (c0) : 24.37 +- 8.50 (19.58, 18.23, 29.40, 15.55, 17.65, 21.51, 43.68, 28.72, 17.14, 32.26)\n",
      "appearance (c1) : 25.52 +- 9.17 (19.68, 18.29, 31.19, 17.33, 18.09, 22.02, 45.83, 30.74, 17.46, 34.62)\n",
      "position (all): 7.75 +- 1.64 (7.56, 6.66, 5.48, 6.72, 9.51, 5.96, 11.10, 8.08, 7.33, 9.06)\n",
      "position (c0) : 7.68 +- 1.70 (7.47, 6.51, 5.09, 6.93, 10.14, 6.01, 10.95, 7.96, 7.34, 8.35)\n",
      "position (c1) : 7.82 +- 1.82 (7.29, 6.33, 5.38, 6.81, 10.42, 6.12, 11.28, 8.22, 7.26, 9.07)\n",
      "relative_position (all): 0.00 +- 0.00 (0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00)\n",
      "relative_position (c0) : 0.00 +- 0.00 (0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00)\n",
      "relative_position (c1) : 0.00 +- 0.00 (0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train / hybrid\n",
    "seeds = range(10)\n",
    "n_epochs = 4000\n",
    "report_every_n = 2000\n",
    "lr = 4e-3\n",
    "d = 1\n",
    "n_classes = 2\n",
    "pos_emb = 'absolute'\n",
    "use_rel_pos = True\n",
    "\n",
    "run_appearance(seeds, n_epochs, lr, d, n_classes, pos_emb, use_rel_pos, train_images, train_labels, test_images, test_labels, analysis_images, analysis_labels, report_every_n=report_every_n, attribution_method='input_gradient_withnegative')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APE+RPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 1.2754610776901245\n",
      "Epoch 2000: 0.033946048468351364\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.8981919884681702\n",
      "Epoch 2000: 0.024572603404521942\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.7707258462905884\n",
      "Epoch 2000: 0.023593934252858162\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.8461412787437439\n",
      "Epoch 2000: 0.029516253620386124\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.7197996377944946\n",
      "Epoch 2000: 0.022811444476246834\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.691383421421051\n",
      "Epoch 2000: 0.02098246105015278\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.6992994546890259\n",
      "Epoch 2000: 0.020786743611097336\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.7071033716201782\n",
      "Epoch 2000: 0.021307887509465218\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.8632458448410034\n",
      "Epoch 2000: 0.02952173724770546\n",
      "Accuracy: 1.0\n",
      "Epoch 0: 0.879478931427002\n",
      "Epoch 2000: 0.027416177093982697\n",
      "Accuracy: 1.0\n",
      "\n",
      "Without bias:\n",
      "appearance (all): 85.07 +- 11.08 (73.00, 94.00, 93.88, 71.10, 65.52, 82.96, 95.72, 84.76, 99.17, 90.59)\n",
      "appearance (c0) : 78.12 +- 8.14 (73.22, 77.23, 90.03, 69.29, 63.57, 82.72, 82.96, 84.97, 71.05, 86.18)\n",
      "appearance (c1) : 95.73 +- 3.22 (98.48, 94.30, 94.14, 99.74, 99.85, 93.51, 95.75, 91.42, 99.16, 90.92)\n",
      "position (all): 14.93 +- 11.08 (27.00, 6.00, 6.12, 28.90, 34.48, 17.04, 4.28, 15.24, 0.83, 9.41)\n",
      "position (c0) : 21.88 +- 8.14 (26.78, 22.77, 9.97, 30.71, 36.43, 17.28, 17.04, 15.03, 28.95, 13.82)\n",
      "position (c1) : 4.27 +- 3.22 (1.52, 5.70, 5.86, 0.26, 0.15, 6.49, 4.25, 8.58, 0.84, 9.08)\n",
      "relative_position (all): 0.00 +- 0.00 (0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00)\n",
      "relative_position (c0) : 0.00 +- 0.00 (0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00)\n",
      "relative_position (c1) : 0.00 +- 0.00 (0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00)\n",
      "\n",
      "With bias:\n",
      "bias (all): 54.02 +- 10.25 (57.77, 66.26, 47.59, 62.86, 57.65, 55.69, 35.00, 43.40, 68.35, 45.61)\n",
      "bias (c0) : 55.55 +- 12.25 (56.01, 60.65, 49.67, 63.37, 72.86, 60.34, 29.96, 47.36, 70.41, 44.88)\n",
      "bias (c1) : 53.46 +- 11.03 (66.57, 67.36, 44.54, 69.38, 50.84, 53.87, 36.95, 41.38, 58.48, 45.19)\n",
      "appearance (all): 39.34 +- 11.40 (30.83, 31.71, 49.20, 26.41, 27.61, 36.75, 62.22, 47.98, 31.39, 49.28)\n",
      "appearance (c0) : 38.26 +- 10.63 (32.21, 30.39, 47.38, 25.38, 27.10, 37.09, 58.10, 48.12, 29.34, 47.51)\n",
      "appearance (c1) : 40.31 +- 10.58 (32.92, 30.78, 49.93, 30.54, 31.25, 38.16, 60.37, 49.81, 29.50, 49.83)\n",
      "position (all): 6.64 +- 4.48 (11.40, 2.03, 3.21, 10.72, 14.73, 7.56, 2.79, 8.62, 0.26, 5.12)\n",
      "position (c0) : 6.19 +- 4.46 (11.78, 8.96, 2.95, 11.25, 0.04, 2.57, 11.94, 4.52, 0.25, 7.62)\n",
      "position (c1) : 6.23 +- 5.33 (0.51, 1.86, 5.53, 0.08, 17.91, 7.97, 2.68, 8.81, 12.02, 4.98)\n",
      "relative_position (all): 0.00 +- 0.00 (0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00)\n",
      "relative_position (c0) : 0.00 +- 0.00 (0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00)\n",
      "relative_position (c1) : 0.00 +- 0.00 (0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train / hybrid\n",
    "seeds = range(10)\n",
    "n_epochs = 4000\n",
    "report_every_n = 2000\n",
    "lr = 4e-3\n",
    "d = 1\n",
    "n_classes = 2\n",
    "pos_emb = 'absolute'\n",
    "use_rel_pos = True\n",
    "\n",
    "run_appearance(seeds, n_epochs, lr, d, n_classes, pos_emb, use_rel_pos, train_images, train_labels, test_images, test_labels, analysis_images, analysis_labels, report_every_n=report_every_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('vit')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a95f2993495c6408642ff11835c089ad7be69b3fd867463ffeddef912e9cf373"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
